"""
HuggingFace Block Loader Test Suite
====================================
hf_loader.py'nin temel fonksiyonlarÄ±nÄ± test eder.

KullanÄ±m:
    python test_hf_loader.py
    
    # Sadece belirli testleri Ã§alÄ±ÅŸtÄ±r:
    python test_hf_loader.py --test basic
    python test_hf_loader.py --test save_load
    python test_hf_loader.py --test generate
"""

import torch
import torch.nn as nn
import argparse
import sys
import os

# swarm_llm'i import et
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from swarm_llm.hf_loader import (
    HuggingFaceBlockLoader,
    QwenBlockWrapper,
    TupleCleaner,
    _StateDictModule,
)
from swarm_llm.external_router import ExternalParisiNashRouter


# â”€â”€ Dummy Model (Test iÃ§in) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
class DummyLayer(nn.Module):
    """Basit transformer katman simÃ¼lasyonu."""
    def __init__(self, dim):
        super().__init__()
        self.norm = nn.LayerNorm(dim)
        self.linear = nn.Linear(dim, dim)
    
    def forward(self, x, **kwargs):
        return (self.linear(self.norm(x)),)  # Tuple dÃ¶ndÃ¼r (HF standardÄ±)


class DummyModel(nn.Module):
    """HuggingFace model simÃ¼lasyonu (Llama/Qwen yapÄ±sÄ±)."""
    def __init__(self, vocab_size=100, embed_dim=64, num_layers=8):
        super().__init__()
        self.model = nn.Module()
        self.model.embed_tokens = nn.Embedding(vocab_size, embed_dim)
        self.model.layers = nn.ModuleList([DummyLayer(embed_dim) for _ in range(num_layers)])
        self.model.norm = nn.LayerNorm(embed_dim)
        self.lm_head = nn.Linear(embed_dim, vocab_size, bias=False)
    
    def parameters(self):
        params = []
        params.extend(self.model.embed_tokens.parameters())
        for layer in self.model.layers:
            params.extend(layer.parameters())
        params.extend(self.model.norm.parameters())
        params.extend(self.lm_head.parameters())
        return iter(params)


class DummyTokenizer:
    """Basit tokenizer simÃ¼lasyonu."""
    def __init__(self, vocab_size=100):
        self.vocab_size = vocab_size
        self.pad_token = None
        self.eos_token = "<eos>"
        self._vocab = {f"token_{i}": i for i in range(vocab_size)}
    
    def get_vocab(self):
        return self._vocab
    
    def encode(self, text, return_tensors=None, add_special_tokens=True):
        # Basit karakter-bazlÄ± tokenizasyon
        tokens = [hash(word) % self.vocab_size for word in text.split()]
        if not tokens:
            tokens = [0]
        if return_tensors == "pt":
            return torch.tensor([tokens], dtype=torch.long)
        return tokens
    
    def decode(self, token_ids, skip_special_tokens=True):
        # Basit decode
        words = [f"w{tid}" for tid in token_ids]
        return " ".join(words)


# â”€â”€ Test FonksiyonlarÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def test_basic_initialization():
    """Test 1: Temel baÅŸlatma ve bloklara bÃ¶lme."""
    print("\n" + "="*60)
    print("TEST 1: Temel BaÅŸlatma ve Bloklara BÃ¶lme")
    print("="*60)
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        num_blocks=4,
        top_k=2,
        device="cpu",
    )
    
    assert len(loader.blocks) == 4, f"Blok sayÄ±sÄ± 4 olmalÄ±, {len(loader.blocks)} bulundu"
    assert loader.top_k == 2, f"top_k 2 olmalÄ±, {loader.top_k} bulundu"
    assert loader.layers_per_block == 2, f"layers_per_block 2 olmalÄ±, {loader.layers_per_block} bulundu"
    assert loader.embed_dim == 64, f"embed_dim 64 olmalÄ±, {loader.embed_dim} bulundu"
    
    print(f"  âœ… Blok sayÄ±sÄ±: {len(loader.blocks)}")
    print(f"  âœ… top_k: {loader.top_k}")
    print(f"  âœ… layers_per_block: {loader.layers_per_block}")
    print(f"  âœ… embed_dim: {loader.embed_dim}")
    print(f"  âœ… is_qwen: {loader._is_qwen}")
    print("  âœ… TEST 1 BAÅARILI")
    return True


def test_no_sharding():
    """Test 2: No-sharding modu."""
    print("\n" + "="*60)
    print("TEST 2: No-Sharding Modu")
    print("="*60)
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        no_sharding=True,
        device="cpu",
    )
    
    assert len(loader.blocks) == 1, f"No-sharding'de 1 blok olmalÄ±, {len(loader.blocks)} bulundu"
    assert loader.num_blocks == 1
    assert loader.top_k == 1
    
    print(f"  âœ… Blok sayÄ±sÄ±: {len(loader.blocks)} (tek blok)")
    print(f"  âœ… Toplam katman: {len(loader.layers)}")
    print("  âœ… TEST 2 BAÅARILI")
    return True


def test_forward_pass():
    """Test 3: Forward pass testi."""
    print("\n" + "="*60)
    print("TEST 3: Forward Pass")
    print("="*60)
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        num_blocks=4,
        top_k=2,
        device="cpu",
    )
    
    input_ids = torch.tensor([[1, 5, 10, 20]], dtype=torch.long)
    outputs = loader.forward(input_ids)
    
    assert "logits" in outputs, "Ã‡Ä±ktÄ±da 'logits' olmalÄ±"
    assert "hidden_states" in outputs, "Ã‡Ä±ktÄ±da 'hidden_states' olmalÄ±"
    assert "selected_indices" in outputs, "Ã‡Ä±ktÄ±da 'selected_indices' olmalÄ±"
    assert outputs["logits"] is not None, "Logits None olmamalÄ±"
    assert outputs["logits"].shape == (1, 4, 100), f"Logits shape (1,4,100) olmalÄ±, {outputs['logits'].shape} bulundu"
    
    print(f"  âœ… Logits shape: {outputs['logits'].shape}")
    print(f"  âœ… Hidden states shape: {outputs['hidden_states'].shape}")
    print(f"  âœ… SeÃ§ilen bloklar: {outputs['selected_indices']}")
    print(f"  âœ… Router weights: {outputs['router_weights']}")
    print("  âœ… TEST 3 BAÅARILI")
    return True


def test_generate():
    """Test 4: Metin Ã¼retimi testi."""
    print("\n" + "="*60)
    print("TEST 4: Metin Ãœretimi")
    print("="*60)
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        num_blocks=4,
        top_k=2,
        device="cpu",
        sticky_duration=10,
    )
    
    result = loader.generate(
        prompt="test input text",
        max_new_tokens=5,
        temperature=1.0,
        top_k=10,
    )
    
    assert isinstance(result, str), f"SonuÃ§ string olmalÄ±, {type(result)} bulundu"
    assert len(result) > 0, "SonuÃ§ boÅŸ olmamalÄ±"
    
    print(f"  âœ… Ãœretilen metin: '{result}'")
    print("  âœ… TEST 4 BAÅARILI")
    return True


def test_save_and_load():
    """Test 5: Diske kaydetme ve diskten yÃ¼kleme."""
    print("\n" + "="*60)
    print("TEST 5: Diske Kaydetme ve Diskten YÃ¼kleme")
    print("="*60)
    
    import tempfile
    import shutil
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        num_blocks=4,
        top_k=2,
        device="cpu",
    )
    
    # Diske kaydet
    save_dir = tempfile.mkdtemp(prefix="swarm_test_")
    try:
        loader.save_blocks_to_disk(save_dir)
        
        # DosyalarÄ±n oluÅŸtuÄŸunu kontrol et
        expected_files = ["block_0.pt", "block_1.pt", "block_2.pt", "block_3.pt", "router.pt"]
        for f in expected_files:
            path = os.path.join(save_dir, f)
            assert os.path.exists(path), f"{f} bulunamadÄ±!"
            print(f"  âœ… {f} kaydedildi ({os.path.getsize(path) / 1024:.1f} KB)")
        
        # Diskten yÃ¼kle (eager mode)
        loader_loaded = HuggingFaceBlockLoader.from_disk_blocks(
            tokenizer=tokenizer,
            save_dir=save_dir,
            device="cpu",
            lazy_load=False,
        )
        
        assert loader_loaded.num_blocks == 4, "YÃ¼klenen blok sayÄ±sÄ± 4 olmalÄ±"
        assert loader_loaded.top_k == 2, "YÃ¼klenen top_k 2 olmalÄ±"
        assert loader_loaded.embed_dim == 64, "YÃ¼klenen embed_dim 64 olmalÄ±"
        
        print(f"  âœ… Diskten yÃ¼kleme baÅŸarÄ±lÄ± (eager mode)")
        print(f"     Blok sayÄ±sÄ±: {loader_loaded.num_blocks}")
        print(f"     top_k: {loader_loaded.top_k}")
        
        # Diskten yÃ¼kle (lazy mode)
        loader_lazy = HuggingFaceBlockLoader.from_disk_blocks(
            tokenizer=tokenizer,
            save_dir=save_dir,
            device="cpu",
            lazy_load=True,
        )
        
        assert loader_lazy._lazy_load == True
        assert len(loader_lazy._block_paths) == 4
        
        print(f"  âœ… Diskten yÃ¼kleme baÅŸarÄ±lÄ± (lazy mode)")
        print("  âœ… TEST 5 BAÅARILI")
        
    finally:
        shutil.rmtree(save_dir, ignore_errors=True)
    
    return True


def test_predict_blocks():
    """Test 6: Blok tahmin testi."""
    print("\n" + "="*60)
    print("TEST 6: Blok Tahmin (predict_blocks)")
    print("="*60)
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        num_blocks=4,
        top_k=2,
        device="cpu",
    )
    
    block_indices, weights = loader.predict_blocks("test prompt", prefetch=False)
    
    assert len(block_indices) == 2, f"2 blok tahmin edilmeli, {len(block_indices)} bulundu"
    assert all(0 <= idx < 4 for idx in block_indices), "Blok indeksleri 0-3 arasÄ± olmalÄ±"
    
    print(f"  âœ… Tahmin edilen bloklar: {block_indices}")
    print(f"  âœ… AÄŸÄ±rlÄ±klar: {weights.tolist()}")
    print("  âœ… TEST 6 BAÅARILI")
    return True


def test_vram_savings():
    """Test 7: VRAM tasarrufu hesaplama."""
    print("\n" + "="*60)
    print("TEST 7: VRAM Tasarrufu Hesaplama")
    print("="*60)
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        num_blocks=4,
        top_k=2,
        device="cpu",
    )
    
    savings = loader.estimate_vram_savings()
    
    assert "total_params" in savings
    assert "savings_ratio" in savings
    assert savings["savings_ratio"] > 1.0, "Tasarruf oranÄ± 1'den bÃ¼yÃ¼k olmalÄ±"
    
    print(f"  âœ… Toplam parametreler: {savings['total_params']:,}")
    print(f"  âœ… TÃ¼m model VRAM: {savings['total_vram_gb']:.4f} GB")
    print(f"  âœ… Seyrek VRAM: {savings['sparse_vram_gb']:.4f} GB")
    print(f"  âœ… Tasarruf: {savings['savings_ratio']:.1f}x")
    print("  âœ… TEST 7 BAÅARILI")
    return True


def test_sticky_routing():
    """Test 8: Sticky routing testi."""
    print("\n" + "="*60)
    print("TEST 8: Sticky Routing")
    print("="*60)
    
    model = DummyModel(vocab_size=100, embed_dim=64, num_layers=8)
    tokenizer = DummyTokenizer(vocab_size=100)
    
    loader = HuggingFaceBlockLoader(
        model=model,
        tokenizer=tokenizer,
        num_blocks=4,
        top_k=2,
        device="cpu",
        sticky_duration=5,
    )
    
    # Ä°lk forward: sticky blocks ayarlanmalÄ±
    input_ids = torch.tensor([[1, 5, 10]], dtype=torch.long)
    outputs1 = loader.forward(input_ids, current_token_idx=0)
    
    # Sticky blocks'u ayarla
    loader._sticky_blocks = set(outputs1["selected_indices"])
    loader._sticky_until_token = 5
    
    # Ä°kinci forward: aynÄ± bloklar kullanÄ±lmalÄ± (sticky)
    outputs2 = loader.forward(input_ids, current_token_idx=2)
    
    assert set(outputs2["selected_indices"]) == set(outputs1["selected_indices"]), \
        f"Sticky routing aktifken aynÄ± bloklar kullanÄ±lmalÄ±: {outputs1['selected_indices']} vs {outputs2['selected_indices']}"
    
    print(f"  âœ… Ä°lk seÃ§im: {outputs1['selected_indices']}")
    print(f"  âœ… Sticky seÃ§im: {outputs2['selected_indices']} (aynÄ±)")
    print("  âœ… TEST 8 BAÅARILI")
    return True


# â”€â”€ Ana Test Ã‡alÄ±ÅŸtÄ±rÄ±cÄ± â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="HuggingFace Block Loader Test Suite")
    parser.add_argument("--test", type=str, default="all", 
                       choices=["all", "basic", "no_sharding", "forward", "generate", 
                                "save_load", "predict", "vram", "sticky"],
                       help="Hangi testi Ã§alÄ±ÅŸtÄ±racaÄŸÄ±nÄ± seÃ§")
    args = parser.parse_args()
    
    tests = {
        "basic": test_basic_initialization,
        "no_sharding": test_no_sharding,
        "forward": test_forward_pass,
        "generate": test_generate,
        "save_load": test_save_and_load,
        "predict": test_predict_blocks,
        "vram": test_vram_savings,
        "sticky": test_sticky_routing,
    }
    
    print("ğŸ§ª Swarm-LLM HuggingFace Block Loader Test Suite")
    print("=" * 60)
    
    passed = 0
    failed = 0
    errors = []
    
    if args.test == "all":
        test_list = tests.items()
    else:
        test_list = [(args.test, tests[args.test])]
    
    for name, test_fn in test_list:
        try:
            result = test_fn()
            if result:
                passed += 1
            else:
                failed += 1
                errors.append(name)
        except Exception as e:
            failed += 1
            errors.append(f"{name}: {e}")
            import traceback
            traceback.print_exc()
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š SONUÃ‡: {passed} baÅŸarÄ±lÄ±, {failed} baÅŸarÄ±sÄ±z")
    if errors:
        print(f"âŒ BaÅŸarÄ±sÄ±z testler: {errors}")
    else:
        print("âœ… TÃ¼m testler baÅŸarÄ±lÄ±!")
    print("=" * 60)
    
    sys.exit(0 if failed == 0 else 1)
