"""
ğŸ“ OFFLINE ROUTER KALÄ°BRASYONU â€” Mac'te Ã‡alÄ±ÅŸÄ±r!
================================================================
A100 gerektirmez. BloklarÄ± tek tek yÃ¼kleyerek:
1. Teacher logits hesaplar (tÃ¼m bloklar sÄ±rayla)
2. Her 2'li kombo iÃ§in student logits hesaplar
3. En iyi komboyu bulur
4. Router'Ä± eÄŸitir

KullanÄ±m:
    python calibrate_router_offline.py
"""

import os
import sys
import time
import itertools

# MPS bellek limiti kaldÄ±r
os.environ["PYTORCH_MPS_HIGH_WATERMARK_RATIO"] = "0.0"

import torch
import torch.nn.functional as F

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AYARLAR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
SAVE_DIR = "model_blocks_qwen25_7b"
MODEL_NAME = "Qwen/Qwen2.5-7B"
TOP_K = 2  # Router kaÃ§ blok seÃ§ecek
CALIBRATION_FILE = os.path.join(SAVE_DIR, "calibration_data.pt")

CALIBRATION_PROMPTS = [
    "The history of artificial intelligence is",
    "In quantum computing, qubits differ from classical bits because",
    "The most important principles of software engineering include",
    "Climate change affects global ecosystems through",
    "Neural networks learn by adjusting weights through",
]

print("="*60)
print("ğŸ“ OFFLINE ROUTER KALÄ°BRASYONU")
print("="*60)

# â”€â”€ Cihaz â”€â”€
if torch.cuda.is_available():
    device = "cuda"
elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    device = "mps"
else:
    device = "cpu"
print(f"Cihaz: {device}")

# â”€â”€ Tokenizer â”€â”€
from transformers import AutoTokenizer
tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)
print(f"Tokenizer: {tokenizer.vocab_size} token")

# â”€â”€ Dosya kontrolÃ¼ â”€â”€
block_files = sorted([f for f in os.listdir(SAVE_DIR) if f.startswith("block_") and f.endswith(".pt")])
num_blocks = len(block_files)
print(f"Bloklar: {num_blocks} adet")

# â”€â”€ YardÄ±mcÄ±: Tek blok yÃ¼kle, Ã§alÄ±ÅŸtÄ±r, sil â”€â”€
def load_and_run_block(block_idx, hidden_states, position_embeddings, position_ids):
    """Tek bloÄŸu diskten yÃ¼kle, Ã§alÄ±ÅŸtÄ±r, bellekten sil."""
    block_path = os.path.join(SAVE_DIR, f"block_{block_idx}.pt")
    
    # CPU'ya yÃ¼kle (mmap ile)
    try:
        block = torch.load(block_path, map_location='cpu', weights_only=False, mmap=True)
    except TypeError:
        block = torch.load(block_path, map_location='cpu', weights_only=False)
    
    # Dtype uyumu
    block = block.to(dtype=hidden_states.dtype)
    block = block.to(device)
    block.eval()
    
    # Ã‡alÄ±ÅŸtÄ±r
    with torch.no_grad():
        if position_embeddings is not None:
            out = block(hidden_states, position_embeddings=position_embeddings,
                       position_ids=position_ids, attention_mask=None)
        else:
            out = block(hidden_states)
    
    # Ã‡Ä±ktÄ±yÄ± ayrÄ±ÅŸtÄ±r
    if isinstance(out, tuple):
        result = out[0]
    else:
        result = out
    
    # Bellek temizle
    del block
    import gc
    gc.collect()
    if device == "cuda":
        torch.cuda.empty_cache()
    elif device == "mps" and hasattr(torch.mps, 'empty_cache'):
        torch.mps.empty_cache()
    
    return result

# â”€â”€ Router.pt'den embed, norm, lm_head yÃ¼kle â”€â”€
print(f"\nğŸ“¦ Router + embed + norm + lm_head yÃ¼kleniyor...")
router_data = torch.load(os.path.join(SAVE_DIR, "router.pt"), map_location='cpu', weights_only=False)

embed_layer = router_data["embed_layer"].to(device)
final_norm = router_data["final_norm"].to(device)
lm_head = router_data["lm_head"].to(device)
router = router_data["router"]  # CPU'da kalsÄ±n (eÄŸitim iÃ§in)

# Rotary embeddings
rotary_emb = None
rotary_path = os.path.join(SAVE_DIR, "rotary_emb.pt")
if os.path.exists(rotary_path):
    rotary_emb = torch.load(rotary_path, map_location=device, weights_only=False)
    print(f"âœ… Rotary embeddings yÃ¼klendi")

embed_dtype = next(embed_layer.parameters()).dtype
print(f"âœ… Embed/Norm/LM_Head yÃ¼klendi (dtype: {embed_dtype})")

# â”€â”€ YardÄ±mcÄ±: Hidden states â†’ logits â”€â”€
def get_logits(hidden_states):
    """Final norm + LM head ile logits hesapla."""
    x = final_norm(hidden_states.to(final_norm.weight.device))
    return lm_head(x)

# â”€â”€ YardÄ±mcÄ±: Position embeddings hesapla â”€â”€
def get_position_info(seq_len):
    """Position IDs ve position embeddings hesapla."""
    position_ids = torch.arange(seq_len, device=device).unsqueeze(0)
    position_embeddings = None
    if rotary_emb is not None:
        try:
            dummy = torch.zeros(1, seq_len, embed_layer.weight.shape[1], 
                              dtype=embed_dtype, device=device)
            cos, sin = rotary_emb(dummy, position_ids)
            position_embeddings = (cos, sin)
        except Exception as e:
            print(f"âš ï¸  Rotary embeddings hatasÄ±: {e}")
    return position_ids, position_embeddings

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADIM 1: TEACHER LOGITS (TÃ¼m bloklar, sÄ±rayla)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*60}")
print(f"ğŸ“– ADIM 1: Teacher Logits (tÃ¼m {num_blocks} blok)")
print(f"{'='*60}")

teacher_data = []

for p_idx, prompt in enumerate(CALIBRATION_PROMPTS):
    print(f"\n  Prompt {p_idx+1}/{len(CALIBRATION_PROMPTS)}: '{prompt[:50]}...'")
    t0 = time.time()
    
    # Tokenize
    input_ids = tokenizer.encode(prompt, return_tensors="pt").to(device)
    seq_len = input_ids.shape[1]
    
    # Embedding
    x = embed_layer(input_ids).to(dtype=embed_dtype)
    
    # Position
    position_ids, position_embeddings = get_position_info(seq_len)
    
    # TÃ¼m bloklarÄ± sÄ±rayla Ã§alÄ±ÅŸtÄ±r
    for b_idx in range(num_blocks):
        print(f"    Block {b_idx}...", end=" ", flush=True)
        x = load_and_run_block(b_idx, x, position_embeddings, position_ids)
        print("âœ…")
    
    # Teacher logits (CPU'ya taÅŸÄ± â€” kÃ¼Ã§Ã¼k)
    logits = get_logits(x)
    teacher_logits_cpu = logits.detach().cpu().float()
    
    # Hidden state'i de kaydet (router eÄŸitimi iÃ§in)
    embed_hidden = embed_layer(input_ids).detach().cpu().float()
    
    teacher_data.append({
        "prompt": prompt,
        "input_ids": input_ids.cpu(),
        "teacher_logits": teacher_logits_cpu,
        "embed_hidden": embed_hidden,
    })
    
    dt = time.time() - t0
    print(f"  â±ï¸  {dt:.0f}s | Logits boyutu: {teacher_logits_cpu.shape}")
    
    # Bellek temizle
    del x, logits
    import gc
    gc.collect()

print(f"\nâœ… Teacher logits tamamlandÄ±!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADIM 2: STUDENT LOGITS (Her 2'li kombo)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*60}")
print(f"ğŸ“ ADIM 2: Student Logits (C({num_blocks},{TOP_K}) = {len(list(itertools.combinations(range(num_blocks), TOP_K)))} kombo)")
print(f"{'='*60}")

combos = list(itertools.combinations(range(num_blocks), TOP_K))
combo_kl_scores = {}

for c_idx, combo in enumerate(combos):
    combo_kls = []
    print(f"\n  Kombo {c_idx+1}/{len(combos)}: Bloklar {combo}")
    
    for p_idx, data in enumerate(teacher_data):
        input_ids = data["input_ids"].to(device)
        teacher_logits = data["teacher_logits"]
        
        # Embedding
        x = embed_layer(input_ids).to(dtype=embed_dtype)
        
        # Position
        seq_len = input_ids.shape[1]
        position_ids, position_embeddings = get_position_info(seq_len)
        
        # Sadece seÃ§ilen bloklarÄ± Ã§alÄ±ÅŸtÄ±r (diÄŸerleri identity/skip)
        for b_idx in range(num_blocks):
            if b_idx in combo:
                print(f"    Block {b_idx}...", end=" ", flush=True)
                x = load_and_run_block(b_idx, x, position_embeddings, position_ids)
                print("âœ…", end="")
            # else: identity (x = x)
        
        # Student logits
        student_logits = get_logits(x).detach().cpu().float()
        
        # KL divergence
        teacher_probs = F.log_softmax(teacher_logits, dim=-1)
        student_probs = F.log_softmax(student_logits, dim=-1)
        kl = F.kl_div(student_probs, teacher_probs.exp(), reduction='batchmean', log_target=False)
        combo_kls.append(kl.item())
        
        # Temizle
        del x, student_logits
        import gc
        gc.collect()
    
    avg_kl = sum(combo_kls) / len(combo_kls)
    combo_kl_scores[combo] = avg_kl
    print(f"\n  ğŸ“Š KL divergence: {avg_kl:.4f}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADIM 3: EN Ä°YÄ° KOMBOYU BUL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*60}")
print(f"ğŸ† SONUÃ‡LAR:")
print(f"{'='*60}")

sorted_combos = sorted(combo_kl_scores.items(), key=lambda x: x[1])

for i, (combo, kl) in enumerate(sorted_combos):
    marker = "ğŸ¥‡" if i == 0 else "ğŸ¥ˆ" if i == 1 else "ğŸ¥‰" if i == 2 else "  "
    print(f"  {marker} Bloklar {combo}: KL = {kl:.4f}")

best_combo = sorted_combos[0][0]
best_kl = sorted_combos[0][1]
print(f"\nğŸ† EN Ä°YÄ° KOMBO: Bloklar {best_combo} (KL = {best_kl:.4f})")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ADIM 4: ROUTER EÄÄ°TÄ°MÄ°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print(f"\n{'='*60}")
print(f"ğŸ“ ADIM 4: Router EÄŸitimi")
print(f"{'='*60}")

# Hedef daÄŸÄ±lÄ±m: En iyi 3 kombo Ã¼zerinden keskin softmax
top3 = sorted_combos[:3]
target_scores = torch.zeros(num_blocks)
for combo, kl in top3:
    # DÃ¼ÅŸÃ¼k KL = iyi â†’ yÃ¼ksek skor
    score = 1.0 / (kl + 1e-8)
    for b in combo:
        target_scores[b] += score

# Softmax ile normalize et (keskin daÄŸÄ±lÄ±m)
target_dist = F.softmax(target_scores / 0.1, dim=0)
print(f"  Hedef daÄŸÄ±lÄ±m: {[f'{v:.3f}' for v in target_dist.tolist()]}")

# Router'Ä± eÄŸit
router_dtype = next(router.parameters()).dtype
router = router.float()  # EÄŸitim iÃ§in float32
optimizer = torch.optim.Adam(router.parameters(), lr=1e-3)

for step in range(200):
    total_loss = 0
    for data in teacher_data:
        embed_hidden = data["embed_hidden"].to('cpu')
        
        # Router Ã§Ä±ktÄ±sÄ±
        probs, indices, aux_loss, weights = router(embed_hidden, pool_input=True)
        
        # Cross-entropy: Router'Ä±n Ã§Ä±ktÄ±sÄ±nÄ± hedef daÄŸÄ±lÄ±ma yaklaÅŸtÄ±r
        router_log_probs = torch.log(probs.squeeze() + 1e-10)
        loss = F.kl_div(router_log_probs, target_dist, reduction='batchmean')
        
        if aux_loss is not None:
            loss = loss + 0.01 * aux_loss
        
        total_loss += loss.item()
        
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
    
    if step % 50 == 0:
        print(f"  AdÄ±m {step}/200: loss = {total_loss/len(teacher_data):.4f}")

# Inference temperature'Ä± dÃ¼ÅŸÃ¼r (keskin seÃ§im)
router.current_temperature = 0.5
router = router.to(dtype=router_dtype)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KAYDET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Router'Ä± gÃ¼ncelle
router_data["router"] = router
torch.save(router_data, os.path.join(SAVE_DIR, "router.pt"))

# Kalibrasyon verilerini de kaydet (debug iÃ§in)
calibration_info = {
    "combo_kl_scores": combo_kl_scores,
    "best_combo": best_combo,
    "best_kl": best_kl,
    "target_dist": target_dist,
    "sorted_combos": sorted_combos,
}
torch.save(calibration_info, CALIBRATION_FILE)

print(f"\nâœ… Router gÃ¼ncellendi: {SAVE_DIR}/router.pt")
print(f"âœ… Kalibrasyon verisi: {CALIBRATION_FILE}")
print(f"\nğŸ¯ ArtÄ±k top_k={TOP_K} ile Ã§alÄ±ÅŸtÄ±rabilirsin:")
print(f"   Sadece bloklar {best_combo} yÃ¼klenecek")
print(f"   Disk I/O: {num_blocks}Ã—1.8 GB â†’ {TOP_K}Ã—1.8 GB ({TOP_K*1.8:.1f} GB)")
print(f"   HÄ±z: ~{num_blocks/TOP_K:.1f}x daha hÄ±zlÄ±")
