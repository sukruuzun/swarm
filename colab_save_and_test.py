"""
ğŸ¯ TEK AMAÃ‡: Qwen 7B'yi bloklara bÃ¶l, Drive'a kaydet, lazy loading test et.
================================================================
Colab notebook'ta Ã§alÄ±ÅŸtÄ±r (script deÄŸil, hÃ¼crelere yapÄ±ÅŸtÄ±r):

HÃœCRE 1: Kurulum
HÃœCRE 2: Model yÃ¼kle + bloklara bÃ¶l + kaydet
HÃœCRE 3: Drive'a kopyala
HÃœCRE 4: Sequential Lazy Loading testi
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HÃœCRE 1: KURULUM (Bu hÃ¼creyi ilk Ã§alÄ±ÅŸtÄ±r)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("ğŸ“¦ Kurulum baÅŸlÄ±yor...")

import subprocess, sys, os

# Gerekli paketler
subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", 
                       "torch", "transformers", "accelerate", "huggingface_hub"])

# Repo'yu klonla (yoksa)
if not os.path.exists("/content/swarm"):
    subprocess.check_call(["git", "clone", "https://github.com/sukruuzun/swarm.git", "/content/swarm"])
else:
    subprocess.check_call(["git", "-C", "/content/swarm", "pull"])

sys.path.insert(0, "/content/swarm")

print("âœ… Kurulum tamamlandÄ±!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HÃœCRE 2: MODEL YÃœKLE + BLOKLARA BÃ–L + KAYDET
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "="*60)
print("ğŸš€ MODEL YÃœKLEME + SHARDING")
print("="*60)

import torch

# GPU kontrolÃ¼
print(f"CUDA: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"GPU: {torch.cuda.get_device_name(0)}")
    print(f"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# HF Token
hf_token = os.environ.get("HF_TOKEN")
if not hf_token:
    try:
        from google.colab import userdata
        hf_token = userdata.get('HF_TOKEN')
    except:
        pass
if not hf_token:
    hf_token = input("HF Token girin: ").strip()
print(f"âœ… Token {'bulundu' if hf_token else 'BULUNAMADI!'}")

# Model yÃ¼kle
MODEL_NAME = "Qwen/Qwen2.5-7B"
SAVE_DIR = "model_blocks_qwen25_7b"
NUM_BLOCKS = 7

print(f"\nğŸ”„ {MODEL_NAME} yÃ¼kleniyor...")
from transformers import AutoTokenizer, AutoModelForCausalLM

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, token=hf_token, trust_remote_code=True)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME, 
    token=hf_token, 
    trust_remote_code=True,
    torch_dtype=torch.float16, 
    device_map="auto"
)
print(f"âœ… Model yÃ¼klendi: {sum(p.numel() for p in model.parameters()) / 1e9:.1f}B parametre")

# Bloklara bÃ¶l ve kaydet
print(f"\nğŸ“¦ {NUM_BLOCKS} bloÄŸa bÃ¶lÃ¼nÃ¼yor...")
from swarm_llm.hf_loader import HuggingFaceBlockLoader

loader = HuggingFaceBlockLoader(
    model=model,
    tokenizer=tokenizer,
    num_blocks=NUM_BLOCKS,
    top_k=2,
    no_sharding=False,
)

print(f"\nğŸ’¾ Diske kaydediliyor: {SAVE_DIR}/")
loader.save_blocks_to_disk(SAVE_DIR)

# Dosya listesi
print(f"\nğŸ“‚ Kaydedilen dosyalar:")
total_mb = 0
for f in sorted(os.listdir(SAVE_DIR)):
    if f.endswith('.pt'):
        size_mb = os.path.getsize(os.path.join(SAVE_DIR, f)) / (1024**2)
        total_mb += size_mb
        print(f"   {f}: {size_mb:.0f} MB")
print(f"   TOPLAM: {total_mb:.0f} MB ({total_mb/1024:.1f} GB)")

print("\nâœ… BLOKLAMA TAMAMLANDI!")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HÃœCRE 3: GOOGLE DRIVE'A KOPYALA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "="*60)
print("ğŸ“ GOOGLE DRIVE'A KOPYALAMA")
print("="*60)

from google.colab import drive
drive.mount('/content/drive')

import shutil

DRIVE_TARGET = "/content/drive/MyDrive/swarm_model_blocks"
os.makedirs(DRIVE_TARGET, exist_ok=True)

files_copied = 0
for fname in sorted(os.listdir(SAVE_DIR)):
    if fname.endswith('.pt'):
        src = os.path.join(SAVE_DIR, fname)
        dst = os.path.join(DRIVE_TARGET, fname)
        size_mb = os.path.getsize(src) / (1024**2)
        print(f"   ğŸ“„ {fname} ({size_mb:.0f} MB) â†’ Drive...", end=" ", flush=True)
        shutil.copy2(src, dst)
        print("âœ…")
        files_copied += 1

print(f"\nâœ… {files_copied} dosya Google Drive'a kopyalandÄ±!")
print(f"ğŸ“ Konum: My Drive/swarm_model_blocks/")
print(f"\nğŸ’¡ PC'ye Ä°ndirme:")
print(f"   1. drive.google.com â†’ 'swarm_model_blocks' klasÃ¶rÃ¼")
print(f"   2. TÃ¼m .pt dosyalarÄ±nÄ± indir")
print(f"   3. Toplam ~14.5 GB")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HÃœCRE 4: SEQUENTIAL LAZY LOADING TESTÄ° (Opsiyonel)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
print("\n" + "="*60)
print("ğŸ§ª SEQUENTIAL LAZY LOADING TESTÄ°")
print("="*60)
print("   TÃ¼m bloklar sÄ±rayla Ã§alÄ±ÅŸÄ±r â€” tam kalite + dÃ¼ÅŸÃ¼k VRAM")

# Model'i bellekten kaldÄ±r
del model
del loader
torch.cuda.empty_cache()
print("ğŸ—‘ï¸  Orijinal model bellekten silindi")

# Diskten lazy load
from swarm_llm.hf_loader import HuggingFaceBlockLoader as Loader

lazy_loader = Loader.from_disk_blocks(
    tokenizer=tokenizer,
    save_dir=SAVE_DIR,
    device="auto",
    lazy_load=True,
    sequential_all=True,  # TÃ¼m bloklar sÄ±rayla â†’ tam kalite
)

print(f"\nğŸ”„ Metin Ã¼retimi (sequential lazy)...")
prompt = "The history of artificial intelligence is"
generated = lazy_loader.generate(
    prompt=prompt,
    max_new_tokens=80,
    temperature=0.8,
    top_k=40,
)

print(f"\nğŸ“ Prompt: '{prompt}'")
print(f"ğŸ“ Ãœretilen: '{generated}'")

# VRAM kontrolÃ¼
if torch.cuda.is_available():
    allocated = torch.cuda.memory_allocated() / 1e9
    print(f"\nğŸ’¾ VRAM kullanÄ±mÄ±: {allocated:.1f} GB (tam model: ~14 GB)")

lazy_loader.stop_prefetching()
print("\nâœ… TEST TAMAMLANDI!")
print("\nğŸ‰ ArtÄ±k .pt dosyalarÄ±nÄ± Drive'dan indir ve kendi Mac'inde Ã§alÄ±ÅŸtÄ±r!")
